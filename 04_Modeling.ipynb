{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c2459-a019-41df-b92f-1fea725ffea2",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af484750-ff26-4c78-9fa7-7f8fc8dc0594",
   "metadata": {},
   "source": [
    "\n",
    "# Project 3.03 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ba893-b0b4-4f0c-81d1-3edb7fc527ba",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Functions](#Functions)\n",
    "\n",
    "- [Imports](#Imports)\n",
    "\n",
    "- [Null Hypothesis](#Null-Hypothesis) \n",
    "\n",
    "- [Model Pre-processing](#Model-Pre_Processing)\n",
    "\n",
    "- [Vector Selection](#Vector-Selection)\n",
    "\n",
    "- [Logistic Regression](#Logistic-Regression)\n",
    "\n",
    "- [Multinomial Naive Bayes](#Multinomial-Naive-Bayes)\n",
    "\n",
    "- [Random Forest](#Random-Forest)\n",
    "\n",
    "- [K Nearest Neighbors](#K-Nearest-Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98442a36-001d-45ac-96e7-f96f5bd35078",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70ea2839-d471-48e9-9d9d-d31006d6581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#Import Cleaning and Viz packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "\n",
    "#Import SK Learn Modeling Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68d50cd0-bed1-43a1-b0ee-f560354ede11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date created (epoch time)</th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "      <th>upvote score</th>\n",
       "      <th>number of comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>lemmatized_tokenized_words</th>\n",
       "      <th>stemmatized_tokenized_words</th>\n",
       "      <th>post_reddit_finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kmuinnovation</td>\n",
       "      <td>1631255155</td>\n",
       "      <td>plfj7f</td>\n",
       "      <td>Schweizer Kredit Rangliste des Monats Septembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>['schweizer', 'kredit', 'rangliste', 'des', 'm...</td>\n",
       "      <td>['schweizer', 'kredit', 'rangliste', 'de', 'mo...</td>\n",
       "      <td>['schweizer', 'kredit', 'ranglist', 'de', 'mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sillychillly</td>\n",
       "      <td>1631255546</td>\n",
       "      <td>plfm8v</td>\n",
       "      <td>Mastercard acquires CipherTrace to enhance cry...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>['mastercard', 'acquires', 'ciphertrace', 'to'...</td>\n",
       "      <td>['mastercard', 'acquires', 'ciphertrace', 'to'...</td>\n",
       "      <td>['mastercard', 'acquir', 'ciphertrac', 'to', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author  date created (epoch time) post_id  \\\n",
       "0  kmuinnovation                 1631255155  plfj7f   \n",
       "1   sillychillly                 1631255546  plfm8v   \n",
       "\n",
       "                                                body  upvote score  \\\n",
       "0  Schweizer Kredit Rangliste des Monats Septembe...             1   \n",
       "1  Mastercard acquires CipherTrace to enhance cry...             1   \n",
       "\n",
       "   number of comments subreddit  length  word_count  \\\n",
       "0                   0   Finance      52           7   \n",
       "1                   0   Finance      62           7   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  ['schweizer', 'kredit', 'rangliste', 'des', 'm...   \n",
       "1  ['mastercard', 'acquires', 'ciphertrace', 'to'...   \n",
       "\n",
       "                          lemmatized_tokenized_words  \\\n",
       "0  ['schweizer', 'kredit', 'rangliste', 'de', 'mo...   \n",
       "1  ['mastercard', 'acquires', 'ciphertrace', 'to'...   \n",
       "\n",
       "                         stemmatized_tokenized_words  post_reddit_finance  \n",
       "0  ['schweizer', 'kredit', 'ranglist', 'de', 'mon...                    1  \n",
       "1  ['mastercard', 'acquir', 'ciphertrac', 'to', '...                    1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import dataframe\n",
    "df1 = pd.read_csv('./Data/Reddit_Posts.csv')\n",
    "\n",
    "df1.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72eaaa-6419-4c25-97f3-c95704978163",
   "metadata": {},
   "source": [
    "**The stopwords added in our prior EDA work will be returned here to factor into our modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f883b876-3195-46d5-bd01-938c3cac0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_word=['the', 'to','in','of', 'and', 'for', \n",
    "                  'is','on', 'with', 'com', 'https', 'www', \n",
    "                  'content', 'tinyurl', 'wp', 'uploads', 'jpg', '2020', \n",
    "                  '2021', 'pdf', 'amp', '10', '19'] \n",
    "\n",
    "#Create stopwords variable\n",
    "stopwords_1 = stopwords.words('english')\n",
    "stopwords_1 = custom_stop_word + stopwords_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba5d3a-a01a-43cf-a5ac-9f2057562292",
   "metadata": {},
   "source": [
    "## Null Hypothesis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Our Null Hypothesis for this classification problem is .5, based off of the random chance of picking one prediction over another, as we are making a classification prediction between two subreddits of a similar shape. This null hypothesis will alternate accordingly if subreddit data sources are changed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74d1fb86-809f-4a4f-a42f-73573e5f5846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500025\n",
       "1    0.499975\n",
       "Name: post_reddit_finance, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Develop Null Hypothesis\n",
    "df1['post_reddit_finance'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa2a90-5f66-4cbb-ba4e-160ab75eaf4f",
   "metadata": {},
   "source": [
    "## Models Represented\n",
    "\n",
    "**The models we will be running are as follows**\n",
    "\n",
    "\n",
    "- Logistic Regression (count vect. and a tfidf vect.)\n",
    "- Multinomial Naive Bayes (tfidf vect. and a Gridsearch)\n",
    "- Random Forest (tfidf vect. and a Gridsearch)\n",
    "- KNN Neighbors (tfidf vect. and a Gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d113bc-164d-4964-9472-d50ec27c5424",
   "metadata": {},
   "source": [
    "## Vector Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a022f-8cbd-4af7-9b5b-6985d04c996f",
   "metadata": {},
   "source": [
    "**Our target variable will be whether a post belongs to reddit finance or not.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d07ffba-c37b-4183-b4c9-1d81a7c54165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "14000\n",
      "6001\n",
      "6001\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = df1['body']\n",
    "y = df1['post_reddit_finance']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.30, \n",
    "                                                    random_state=42, stratify = y)\n",
    "\n",
    "#Check shape to make sure it matches\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39e833-81cf-4824-b03f-157e35440a62",
   "metadata": {},
   "source": [
    "#### Count Vectorizer\n",
    "\n",
    "**Here we instantiate our vectorizer with our custom stop word list and an ngram_range of [1,2]. Our stop word list while our ingram range pushes the analyzer to capture complex expressions formed by the composition of more than one word. (So instead of \"not, good,\" the analyzer recognizes \"not good\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa809d0c-aa87-4916-aad9-46cb9eb74f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14000x106326 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 235722 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Count Vectorizer\n",
    "cvec = CountVectorizer(stop_words = stopwords_1, ngram_range=(1,2))\n",
    "cvec.fit(X_train)\n",
    "\n",
    "#Transform vector\n",
    "X_train_cv = cvec.transform(X_train)\n",
    "X_test_cv = cvec.transform(X_test)\n",
    "\n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeefe3b-a6bc-4569-b477-019e7da3ccd2",
   "metadata": {},
   "source": [
    "#### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5982ee20-4c84-400b-8957-e98e87765e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Instantiate Vectorizer\n",
    "tvec = TfidfVectorizer(stop_words= stopwords_1, ngram_range=(1,2))\n",
    "\n",
    "#Transform Vector\n",
    "X_train_TF = tvec.fit_transform(X_train)\n",
    "X_test_TF = tvec.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4093618-5e4b-42ba-b685-396e7340578b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76903db6-2522-41ad-b1ce-1061644b8565",
   "metadata": {},
   "source": [
    "**We run Logistic Regressions as a means to test the effectiveness of our vectorizers. Our regression off of a count vectorizer scored a 75% accuracy on unseen data, while our TFidf Vectorizer scored 76%**. \n",
    "\n",
    "**While the scoring is similar, our count vectorized regression is more overfit, which was expected because it typically results in bias for more frequent words, while a Tfidf Vectorizer penalizes these values and analyzes more factors. We will use our Tfidf Vectorizer for the bulk of our modeling**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dec30e29-7a3f-4dd6-aa10-0a2ac4fc9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9725714285714285\n",
      "Testing score: 0.7582069655057491\n",
      "[[-0.11347765  0.02551134  0.00638595 ...  0.06666518  0.06666518\n",
      "   0.06666518]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with Count Vectorizer\n",
    "lr_model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "lr_model.fit(X_train_cv, y_train)\n",
    "\n",
    "\n",
    "score = lr_model.score(X_train_cv, y_train)\n",
    "score_test = lr_model.score(X_test_cv, y_test)\n",
    "\n",
    "print('Training score:',score)\n",
    "print('Testing score:',score_test)\n",
    "\n",
    "importance = lr_model.coef_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25c232d8-6383-4357-9e83-84275159941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.921\n",
      "Testing Score: 0.7688718546908848\n",
      "[[-0.11347765  0.02551134  0.00638595 ...  0.06666518  0.06666518\n",
      "   0.06666518]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with TFID Vectorizer\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "lr.fit(X_train_TF, y_train)\n",
    "\n",
    "# Score model on train data\n",
    "score = lr.score(X_train_TF, y_train)\n",
    "test_score = lr.score(X_test_TF, y_test)\n",
    "\n",
    "\n",
    "print('Training Score:',score)\n",
    "print('Testing Score:',test_score)\n",
    "\n",
    "importance = lr_model.coef_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a4872-875e-4aed-af7c-f04c3112320c",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "\n",
    "**We run a Multinomial Naive Bayes as it tends to test well on discrete features, which our array is**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "399974a6-85c9-49a3-8bb8-60b185e1a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657057157140477\n",
      "True Negatives: 2448\n",
      "False Positives: 553\n",
      "False Negatives: 853\n",
      "True Positives: 2147\n",
      "Accuracy: 0.7657057157140477\n",
      "Specificity: 0.8157280906364545\n",
      "Precision: 0.7951851851851852\n",
      "Recall: 0.7156666666666667\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha = 1)\n",
    "\n",
    "nb.fit(X_train_TF, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test_TF)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "\n",
    "# calculate Accuracy (Total correct)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %s\" %acc)\n",
    "\n",
    "# Calculate the specificity (True negative)\n",
    "spec = tn/(tn + fp)\n",
    "print(\"Specificity: %s\" %spec)\n",
    "\n",
    "# calculate precision\n",
    "prec = tp / (tp + fp)\n",
    "print(\"Precision: %s\" %prec)\n",
    "\n",
    "# calculate recall \n",
    "rec = tp / (tp + fn)\n",
    "print(\"Recall: %s\" %rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4176c-255e-4913-988b-dc40e5dc0b6f",
   "metadata": {},
   "source": [
    "**Our standard, unoptimized version runs at .76** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13edd3-ce5b-41da-8186-9fd634e2c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "mb_pipe = Pipeline([('tvec', TfidfVectorizer(stop_words=stopwords_1, max_features=500, ngram_range=(1,2))),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "mb_params = {\n",
    "    'mnb__alpha': [0.01, 0.1, 0.5, 1.0, 10.0], \n",
    "    'mnb__fit_prior': [True]\n",
    "}\n",
    "\n",
    "\n",
    "# Set up a gridsearch\n",
    "mb_TF = GridSearchCV(mb_pipe, mb_params, cv=10, verbose=1)\n",
    "\n",
    "# Fit the gridsearch\n",
    "mb_TF.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5f370-ae8b-4688-9244-1805e3769d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the best score\n",
    "print(\"Best Score: %s\" % mb_TF.best_score_)\n",
    "\n",
    "# What are the best hyperparameters?\n",
    "print(\"Best Params: %s\" % mb_TF.best_params_)\n",
    "\n",
    "# Score model on testing set\n",
    "print(\"Training Score: %s\"% mb_TF.score(X_train, y_train))\n",
    "print(\"Test Score: %s\" % mb_TF.score(X_test, y_test))\n",
    "\n",
    "preds = mb_TF.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b982be-5ba7-4ff4-8e00-3f2d6c428196",
   "metadata": {},
   "source": [
    "**Our multinomial model scored relatively well in terms of our training and test score (.74,.73). The score itself appears to be having a good degree of fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bab88-18a0-4648-b45e-4dfaf5d1120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate metrics\n",
    "\n",
    "# calculate Accuracy (Total correct)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %s\" %acc)\n",
    "\n",
    "# Calculate the specificity (True negative)\n",
    "spec = tn/(tn + fp)\n",
    "print(\"Specificity: %s\" %spec)\n",
    "\n",
    "# calculate precision\n",
    "prec = tp / (tp + fp)\n",
    "print(\"Precision: %s\" %prec)\n",
    "\n",
    "# calculate recall \n",
    "rec = tp / (tp + fn)\n",
    "print(\"Recall: %s\" %rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcf2ceb-c894-4bbc-b355-b9250fd7dd0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79f71e4aeeb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_TF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(mb_TF, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf84bc7-5670-4afe-a628-8807b3c2ac7c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386824d-1766-4571-841c-d072ba9bac3b",
   "metadata": {},
   "source": [
    "**As a tree algorithm, a Random Forest selects randomized subsets of data, contrary to a regular decision tree, preventing one or a few features that are are very strong predictors for the response variable (target y) being correlated the This randomness results in a wide diversity that generally results in a better model.**\n",
    "\n",
    "**In this case, our unoptimized random forest with a cross val score of 5 ran slightly higher than our optimized model**\n",
    "\n",
    "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
    "0.7515714285714286\n",
    "\n",
    "#Best features\n",
    "{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695115b-bcb6-4ccc-8fd4-a14f2c9726fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687acfb8-57c2-4b31-907c-acd0b4ddbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf, X_train_TF, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d78c2-378d-41c4-a5d7-f1500b169f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100], #200,300,400], #number of trees built before taking averages of predictions\n",
    "    'max_depth': [None,] #1,2,3,4,5], \n",
    "    'max_features': ['sqrt',] #.5] #Number of features considered as the random forest to split a node\n",
    "}\n",
    "\n",
    "rfs = GridSearchCV(rf, rf_params, cv=5, n_jobs=-1, verbose=1) #CV of 10 pushes higher variance, reducing bias\n",
    "rfs.fit(X_train_TF, y_train)\n",
    "print(rfs.best_score_)\n",
    "rfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f222fb9-bd99-4c18-a5f8-db4cbc31fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897e87d-bee7-4a80-8324-f8cdd6a82d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator Score Train: ', rfs.best_estimator_.score(X_train_TF, y_train))\n",
    "print('Best Estimator Score Test: ', rfs.best_estimator_.score(X_test_TF, y_test))\n",
    "\n",
    "#Get our matrix results that show our accuracy\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, rfs.predict(X_test_TF)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc07971-d066-44a3-95e0-1a227523defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Accuracy (Total correct)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %s\" %acc)\n",
    "\n",
    "# Calculate the specificity (True negative)\n",
    "spec = tn/(tn + fp)\n",
    "print(\"Specificity: %s\" %spec)\n",
    "\n",
    "# calculate precision\n",
    "prec = tp / (tp + fp)\n",
    "print(\"Precision: %s\" %prec)\n",
    "\n",
    "# calculate recall \n",
    "rec = tp / (tp + fn)\n",
    "print(\"Recall: %s\" %rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da189945-9726-409a-b045-88c8cea5729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rfs, X_test_TF, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e624042-abc6-4abb-9bd4-40c4b2021e92",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "\n",
    "**Our K Neighbors models running unoptimized on our Count Vectorizer were severely overfit to the training data (75% accuracy), given the test recognized 58% of unseen data**\n",
    "\n",
    "**On our TFidf Vectorizer, the unoptimized model improves to 81%, and has a greater degree of fit with the test data (71% Accuracy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a09af8-0fe1-4c15-9309-c5d21f7a3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train_TF, y_train)\n",
    "\n",
    "print('Training set score: ' + str(knn.score(X_train_cv,y_train)))\n",
    "print('Test set score: ' + str(knn.score(X_test_cv,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be2a39-ea6d-4632-984d-e31ab12bf8eb",
   "metadata": {},
   "source": [
    "**Our K Neighbors model running optimized were showed that our most optimized score for our K_Neighbors model was a training score of 75.7%, with a test score of 74%. The optimized model settled on these parameters (n_neighbors = 71, and our metric = euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769356b-b70f-41c9-bbdf-64e8026904dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': range(1, 100),\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Instantiate our GridSearch\n",
    "gs_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(), # what model to fit\n",
    "    knn_params, # dictionary of parameters to search\n",
    "    cv=10, # number of folds (default is 5)\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gs_knn.fit(X_train_TF, y_train)\n",
    "\n",
    "print('Best Params: ',gs_knn.best_params_)\n",
    "print('Best Estimator Score Train: ', gs_knn.best_estimator_.score(X_train_TF, y_train))\n",
    "print('Best Estimator Score Test: ', gs_knn.best_estimator_.score(X_test_TF, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e04f-fc9a-45c3-84db-ea8bec8b592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, gs_knn.predict(X_test_TF)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "# calculate Accuracy (Total correct)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %s\" %acc)\n",
    "\n",
    "# Calculate the specificity (True negative)\n",
    "spec = tn/(tn + fp)\n",
    "print(\"Specificity: %s\" %spec)\n",
    "\n",
    "# calculate precision\n",
    "prec = tp / (tp + fp)\n",
    "print(\"Precision: %s\" %prec)\n",
    "\n",
    "# calculate recall \n",
    "rec = tp / (tp + fn)\n",
    "print(\"Recall: %s\" %rec)\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b06e16-0a4c-4fab-b6a6-6cf64084d3d7",
   "metadata": {},
   "source": [
    "## Model Choice - K-Nearest Neighbors with Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a38d7-4289-4387-ab6e-126f677f380d",
   "metadata": {},
   "source": [
    "In the end, We choose to go with our K-Nearest Neighbors model, with gridsearch parameters of nearest neighbors = 72, and the Euclidean metric. \n",
    "This is because our gridsearch performed well, having the best overall fit of all the data models, and a reasonable degree of accuracy in comparison to the other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
